{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEA resource estimate\n",
    "\n",
    "1. Basic resource estimate equation: from circuit input and backend properties and options estimate resource usage\n",
    "    - resource estimate below is quite off from the qpu runtime\n",
    "    - can we even get a decent estimate on runtime of a circuit??\n",
    "2. Identify what we need to change in this notebook for the working session\n",
    "    - how do the options in the estimator influence the protocol?\n",
    "    - if they try running their circuit of interest and we get back the information on the results/metadata, what can we learn?\n",
    "    - Modify Saki's notebook to take a user defined circuit and do PEA on it with pre-defined options (they can change them if they want) and collect info on execution\n",
    "3. Review survey questions, ensuring that we get the information we need on enabled projects (what do we think we need to know?)\n",
    "    - input circuits\n",
    "    - input metadata \n",
    "    - output metadata\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory on resource estimate\n",
    "\n",
    "1. characterization protocol for each unique layer: resources needed in terms of input/options/backend props\n",
    "    - 9 basis to characterize all 2Q Paulis\n",
    "    - Apply different numbers of 2Q Clifford (CX, CZ, ECR) (depth specified by user -- could estimate given backend properties)\n",
    "    - Specify number of twirls for each cycle benchmarking experiment (rule of thumb is about 30-100)\n",
    "    - Specify number of shots (20 shots per circuit, more or less gives less information per shot)\n",
    "\n",
    "        \n",
    "`TOTAL number of shots =  number_unique_layers*9_basis*number_cycle_depths*number_randomizations*shots_per_randomization` use rep_delay_time for rough time estimate (backend_prop reports rep_delay)\n",
    "\n",
    "\n",
    "2. mitigation protocol: resources needed in terms of input/options/backend props: once we know the layer noise (user know the gamma per circuit):\n",
    "    - number of randomizations (independent of total gamma of circuit)\n",
    "    - number of shots per randomization\n",
    "    - number of noise gains (generally 3+) -- picking the noise gains is non-trivial, could estimate this\n",
    "\n",
    "`TOTAL number of shots = number_of_noise_gains*number_of_randomizations*number_of_shots_per_randomization`\n",
    "\n",
    "\n",
    "\n",
    "#### Notes:\n",
    "- Exclude trex estimation from Estimator job for now\n",
    "- Where is the classical overhead coming from?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimator Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Base option formatting\n",
    "# # Builtin resilience settings for ZNE\n",
    "# options = {\n",
    "#     # Builtin resilience settings for ZNE\n",
    "#         \"resilience\": {\n",
    "#         \"measure_mitigation\": True,\n",
    "#         \"zne_mitigation\": True,\n",
    "#         \"zne\": {\"noise_factors\": noise_factors},\n",
    "\n",
    "        \n",
    "#         # PEA noise model configuration\n",
    "#         \"layer_noise_learning\": {\n",
    "#             \"max_layers_to_learn\": 10, # HOW DO YOU PICK WHICH LAYERS TO LEARN (maybe using backend props to estimate?)\n",
    "#             \"layer_pair_depths\": learning_pair_depths = #[0, 4, 8, 16, 32, 48, 1300], # CHECK DEFAULTS AND GIVE PLAUSIBEL ESTIMATE FROM BACKEND PROPS\n",
    "#             \"shots_per_randomization\": shots_per_randomization, #20 JUSTIFIED BY ANDREW WACK\n",
    "#             \"num_randomizations\": num_randomizations_learning, #30-100 CLARIFY WITH IAN\n",
    "#         },\n",
    "#     },\n",
    "    \n",
    "#     # Randomization configuration\n",
    "#     \"twirling\": {\n",
    "#         \"num_randomizations\": num_randomizations,\n",
    "#         \"shots_per_randomization\": shots_per_randomization,\n",
    "#         \"strategy\": \"all\",\n",
    "#     },\n",
    "\n",
    "#     # Experimental settings for PEA method\n",
    "#     \"experimental\": {\n",
    "#         # # Just in case, disable any further qiskit transpilation not related to twirling / DD\n",
    "#         # \"skip_transpilation\": True,\n",
    "\n",
    "#         # Execution configuration\n",
    "#         \"execution\": {\n",
    "#             \"max_pubs_per_batch_job\": max_batch_circuits,\n",
    "#             \"fast_parametric_update\": True,\n",
    "#         },\n",
    "\n",
    "#         # Error Mitigation configuration\n",
    "#         \"resilience\": {\n",
    "#             # ZNE Configuration\n",
    "#             \"zne\": {\n",
    "#                 \"amplifier\": \"pea\",\n",
    "#                 \"return_all_extrapolated\": True,\n",
    "#                 \"return_unextrapolated\": True,\n",
    "#                 \"extrapolated_noise_factors\": [0, 0.25, 0.5, 0.75] + noise_factors,\n",
    "#                 # MAX NUMBER OF UNIQUE LAYERS TO MITIGATE/MAX NUMBER OF TOTAL SHOTS?\n",
    "#                 # OTHER OPTIONS?\n",
    "#             }\n",
    "#         }\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating depths for cycle benchmarking (noise learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. calcualte number of CXs in least noisy layer\n",
    "\n",
    "# 2. get cx fidelity from reported ELPG (or use reported value to get average CX error)\n",
    "# for el in backend_real.properties().general:\n",
    "\n",
    "#     if el.name[:2] == 'lf' and el.name[3:] == str(num_qubits):\n",
    "#         lf = el.value # layer fidelity\n",
    "#         print('layer fidelity', lf)\n",
    "#         elpg = 1-lf**(1/(num_qubits-1)) # elpg\n",
    "#         # print('ELPG', elpg)\n",
    "#         fid_cx = 1 - elpg\n",
    "\n",
    "# 3. Calculate max number of CXs (or layer reps) to reach 0 fidelity for the least noisy unique layer and derive max number of reps of that layer\n",
    "\n",
    "# 4. pick a logarithmically spaced interval of depths [0, max_layer_depths] with X number of points in the interval\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating noise gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#noise learning gives the total gamma of the circuit = gamma_circ\n",
    "#num_2q_ops number of gates in the circuit\n",
    "gamma_cx = gamma_circ/num_2q_ops\n",
    "# covert to 2q fidelity\n",
    "fid_cx = sqrt(1/gamma_cx)\n",
    "\n",
    "#number of ops before fidelity drops to zero\n",
    "max_num_cx = int(1/(1-fid_cx)) \n",
    "\n",
    "#maximum noise gain is the ratio between the max number of cx \n",
    "max_noise_gain = max_num_cx/num_2q_ops\n",
    "\n",
    "noise_gains = uniform(1, max_noise_gain, number of noise gains) # pick three values of noise gains between 1 and the max uniformly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
