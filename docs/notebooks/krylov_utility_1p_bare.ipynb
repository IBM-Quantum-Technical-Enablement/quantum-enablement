{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating ground states on large scale systems: Quantum Krylov Subspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and definitions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pylab as plt\n",
    "from typing import Union, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from qiskit.quantum_info import SparsePauliOp, Pauli\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit import QuantumCircuit, QuantumRegister, transpile\n",
    "from qiskit.circuit.library import PauliEvolutionGate\n",
    "from qiskit.synthesis import SuzukiTrotter\n",
    "from qiskit.providers.fake_provider import Fake20QV1\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, EstimatorV2 as Estimator\n",
    "\n",
    "import itertools as it\n",
    "\n",
    "def solve_regularized_gen_eig(h: np.ndarray, s:np.ndarray, threshold: float, k: int =1, return_dimn: bool = False) -> Union[float, List[float]]:\n",
    "    \"\"\"\n",
    "    Method for solving the generalized eigenvalue problem with regularization\n",
    "\n",
    "    Args:\n",
    "        h (numpy.ndarray):\n",
    "            The effective representation of the matrix in the Krylov subspace\n",
    "        s (numpy.ndarray):\n",
    "            The matrix of overlaps between vectors of the Krylov subspace\n",
    "        threshold (float):\n",
    "            Cut-off value for the eigenvalue of s\n",
    "        k (int):\n",
    "            Number of eigenvalues to return\n",
    "        return_dimn (bool):\n",
    "            Whether to return the size of the regularized subspace\n",
    "\n",
    "    Returns:\n",
    "        lowest k-eigenvalue(s) that are the solution of the regularized generalized eigenvalue problem\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    s_vals, s_vecs = sp.linalg.eigh(s)\n",
    "    s_vecs = s_vecs.T\n",
    "    good_vecs = np.array([vec for val, vec in zip(s_vals, s_vecs) if val > threshold])\n",
    "    h_reg = good_vecs.conj() @ h @ good_vecs.T\n",
    "    s_reg = good_vecs.conj() @ s @ good_vecs.T\n",
    "    if k==1:\n",
    "        if return_dimn:\n",
    "            return sp.linalg.eigh(h_reg, s_reg)[0][0], len(good_vecs)\n",
    "        else:\n",
    "            return sp.linalg.eigh(h_reg, s_reg)[0][0]\n",
    "    else:\n",
    "        if return_dimn:\n",
    "            return sp.linalg.eigh(h_reg, s_reg)[0][:k], len(good_vecs)\n",
    "        else:\n",
    "            return sp.linalg.eigh(h_reg, s_reg)[0][:k]\n",
    "        \n",
    "\n",
    "\n",
    "def single_particle_gs(H_op, n_qubits):\n",
    "    H_x = []\n",
    "    for p, coeff in H_op.to_list():\n",
    "        H_x.append(set([i for i,v in enumerate(Pauli(p).x) if v]))\n",
    "\n",
    "    H_z = []\n",
    "    for p, coeff in H_op.to_list():\n",
    "        H_z.append(set([i for i,v in enumerate(Pauli(p).z) if v]))\n",
    "\n",
    "    H_c = H_op.coeffs\n",
    "\n",
    "    print('n_sys_qubits', n_qubits)\n",
    "\n",
    "    # n_exc particle Hamiltonian:\n",
    "\n",
    "    n_exc = 1\n",
    "    sub_dimn = int(sp.special.comb(n_qubits+1,n_exc))\n",
    "    print('n_exc', n_exc, ', subspace dimension', sub_dimn)\n",
    "\n",
    "    few_particle_H = np.zeros((sub_dimn,sub_dimn), dtype=complex)\n",
    "\n",
    "    sparse_vecs = [set(vec) for vec in it.combinations(range(n_qubits+1),r=n_exc)] # list all of the possible sets of n_exc indices of 1s in n_exc-particle states\n",
    "\n",
    "    m = 0\n",
    "    for i, i_set in enumerate(sparse_vecs):\n",
    "        for j, j_set in enumerate(sparse_vecs):\n",
    "            m += 1\n",
    "            # if m % int((sub_dimn**2)/100) == 0:\n",
    "            #     print(np.round(m/int((sub_dimn**2)/100),2), '% complete, time =', time.time()-start_time)\n",
    "            #     start_time = time.time()\n",
    "\n",
    "            if len(i_set.symmetric_difference(j_set)) <= 2:\n",
    "\n",
    "                for p_x, p_z, coeff in zip(H_x, H_z, H_c):\n",
    "\n",
    "                    if i_set.symmetric_difference(j_set) == p_x:\n",
    "                        sgn = ((-1j)**len(p_x.intersection(p_z)))*((-1)**len(i_set.intersection(p_z)))\n",
    "                    else:\n",
    "                        sgn = 0\n",
    "\n",
    "                    few_particle_H[i,j] += sgn*coeff\n",
    "\n",
    "    gs_en = min(np.linalg.eigvalsh(few_particle_H))\n",
    "    print('single particle ground state energy: ', gs_en)\n",
    "    return gs_en\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hamiltonian\n",
    "\n",
    "Let's consider the Heisenberg Hamiltonian for $N$ qubits on a linear chain: $H= J \\sum_{i,j}^N X_i X_j + Y_i Y_j - Z_i Z_j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define problem Hamiltonian.\n",
    "n_qubits = 6\n",
    "J = 1 # coupling strength for ZZ interaction\n",
    "\n",
    "# Define the Hamiltonian: \n",
    "H_int = [['I']*n_qubits for _ in range(3*(n_qubits-1))]\n",
    "for i in range(n_qubits-1):\n",
    "    H_int[i][i] = 'Z'\n",
    "    H_int[i][i+1] = 'Z'\n",
    "for i in range(n_qubits-1):\n",
    "    H_int[n_qubits-1+i][i] = 'X'\n",
    "    H_int[n_qubits-1+i][i+1] = 'X'\n",
    "for i in range(n_qubits-1):\n",
    "    H_int[2*(n_qubits-1)+i][i] = 'Y'\n",
    "    H_int[2*(n_qubits-1)+i][i+1] = 'Y'\n",
    "H_int = [''.join(term) for term in H_int]\n",
    "H_tot = [(term, -J) if term.count('Z') == 2 else (term, 1) for term in H_int]\n",
    "\n",
    "# Get operator\n",
    "H_op = SparsePauliOp.from_list(H_tot)\n",
    "print(H_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heuristically choose `dt` (based on upper bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.quantum_info import Pauli\n",
    "# Get Hamiltonian restricted to single-particle states\n",
    "single_particle_H = np.zeros((n_qubits,n_qubits))\n",
    "for i in range(n_qubits):\n",
    "    for j in range(i+1):\n",
    "        for p, coeff in H_op.to_list():\n",
    "            p_x = Pauli(p).x\n",
    "            p_z = Pauli(p).z\n",
    "            if all(p_x[k] == ((i==k)+(j==k))%2 for k in range(n_qubits)):\n",
    "                sgn = ((-1j)**sum(p_z[k] and p_x[k] for k in range(n_qubits)))*((-1)**p_z[i])\n",
    "            else:\n",
    "                sgn = 0\n",
    "            single_particle_H[i,j] += sgn*coeff\n",
    "for i in range(n_qubits):\n",
    "    for j in range(i+1,n_qubits):\n",
    "        single_particle_H[i,j] = np.conj(single_particle_H[j,i])\n",
    "\n",
    "# Set dt according to spectral norm\n",
    "dt = np.pi/np.linalg.norm(single_particle_H, ord=2)\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters for the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for quantum Krylov algorithm\n",
    "krylov_dim = 10 # size of krylov subspace\n",
    "num_trotter_steps = 6\n",
    "dt_circ = dt/num_trotter_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decompose time-evolution operator with Suzuki-Trotter decomposition\n",
    "Instead of implementing the time-evolution operator exactly we can use the Suzuki-Trotter decomposition to implement an approximation of it. Repeating several times a certain order Trotter decomposition gives us further reduction of the error introduced from the approximation. In the following, we directly build the Trotter implementation in the most efficient way for the interaction graph of the Hamiltonian we are considering (nearest neighbor interactions only). In practice we insert Pauli rotations $R_{xx}$, $R_{yy}$, $R_{zz}$ with a parametrized angle $t$ which correspond to the approximate implementation of $e^{-i (XX + YY + ZZ) t}$. This gives a much shallower circuit than what is obtained using the generic `PauliEvolutionGate()` functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Parameter('t')\n",
    "\n",
    "# Create instruction for rotation about XX+YY-ZZ:\n",
    "Rxyz_circ = QuantumCircuit(2)\n",
    "Rxyz_circ.rxx(t,0,1)\n",
    "Rxyz_circ.ryy(t,0,1)\n",
    "Rxyz_circ.rzz(-t,0,1)\n",
    "Rxyz_instr = Rxyz_circ.to_instruction(label='RXX+YY-ZZ')\n",
    "\n",
    "interaction_list = [[[i, i+1] for i in range(0, n_qubits-1, 2)], [[i, i+1] for i in range(1, n_qubits-1, 2)]] # linear chain\n",
    "\n",
    "qr = QuantumRegister(n_qubits)\n",
    "trotter_step_circ = QuantumCircuit(qr)\n",
    "for i, color in enumerate(interaction_list):\n",
    "    for interaction in color:\n",
    "        trotter_step_circ.append(Rxyz_instr, interaction)\n",
    "reverse_trotter_step_circ = trotter_step_circ.reverse_ops()\n",
    "\n",
    "qc_evol = QuantumCircuit(qr)\n",
    "for step in range(num_trotter_steps):\n",
    "    if step % 2 == 0:\n",
    "        qc_evol = qc_evol.compose(trotter_step_circ)\n",
    "    else:\n",
    "        qc_evol = qc_evol.compose(reverse_trotter_step_circ)\n",
    "\n",
    "qc_evol.decompose().draw('mpl', fold=-1, scale = 0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use an optimized circuit for state preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlled_state_prep = QuantumCircuit(n_qubits + 1)\n",
    "controlled_state_prep.cx(0,int(n_qubits/2)+1)\n",
    "controlled_state_prep.draw('mpl', fold=-1, scale=0.5)\n",
    "\n",
    "\n",
    "controlled_state_prep.draw('mpl', fold=-1, scale=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template circuits for calculating matrix elements of $\\tilde{S}$ and $\\tilde{H}$ via Hadamard test\n",
    "The only difference between the circuits used in the Hadamard test will be the phase in the time-evolution operator and the observables measured. Therefore we can prepare a template circuit which represent the generic circuit for the Hadamard test, with placeholders for the gates that depend on the time-evolution operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the template circuits\n",
    "parameters = []\n",
    "for idx_ket in range(1, krylov_dim):\n",
    "    parameters.append(dt_circ*(idx_ket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hadamard test circuit for real part\n",
    "qr = QuantumRegister(n_qubits+1)\n",
    "qc_real = QuantumCircuit(qr)\n",
    "qc_real.h(0)\n",
    "qc_real.compose(controlled_state_prep, list(range(n_qubits+1)), inplace=True)\n",
    "# qc_real.barrier()\n",
    "qc_real.compose(qc_evol, list(range(1, n_qubits+1)), inplace=True)\n",
    "# qc_real.barrier()\n",
    "qc_real.x(0)\n",
    "qc_real.compose(controlled_state_prep.inverse(), list(range(n_qubits+1)), inplace=True)\n",
    "qc_real.x(0)\n",
    "qc_real.h(0)\n",
    "\n",
    "S_real_circ = qc_real.decompose().copy()\n",
    "\n",
    "H_real_circ = qc_real.decompose().copy()\n",
    "\n",
    "# # Create hadamard test circuit for imaginary part\n",
    "qr = QuantumRegister(n_qubits+1)\n",
    "qc_imag = QuantumCircuit(qr)\n",
    "qc_imag.h(0)\n",
    "qc_imag.sdg(0)\n",
    "qc_imag.compose(controlled_state_prep, list(range(n_qubits+1)), inplace=True)\n",
    "# qc_imag.barrier()\n",
    "qc_imag.compose(qc_evol, list(range(1, n_qubits+1)), inplace=True)\n",
    "# qc_imag.barrier()\n",
    "qc_imag.x(0)\n",
    "qc_imag.compose(controlled_state_prep.inverse(), list(range(n_qubits+1)), inplace=True)\n",
    "qc_imag.x(0)\n",
    "qc_imag.h(0)\n",
    "\n",
    "\n",
    "S_imag_circ = qc_imag.decompose().copy()\n",
    "\n",
    "H_imag_circ = qc_imag.decompose().copy()\n",
    "\n",
    "S_real_circ.draw('mpl', fold=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Execute using a quantum primitive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the backend and set runtime parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_ibm_runtime import QiskitRuntimeService, Session, Batch\n",
    "from qiskit_ibm_runtime.fake_provider import FakeTorino, FakeGuadalupeV2\n",
    "from qiskit_aer import AerSimulator\n",
    "\n",
    "\n",
    "SIM = False\n",
    "NOISE = False\n",
    "# service = QiskitRuntimeService(instance='ibm-q-internal/technical-enable/utokyol3enableme')#\n",
    "# service = QiskitRuntimeService(instance='quantum-demonstrations/main/krylov-gs')\n",
    "# service = QiskitRuntimeService(instance='ibm-q-internal/performance/reservations')\n",
    "# service = QiskitRuntimeService(name=\"staging\", instance='ibm-q-internal/internal-test/fast-flux')\n",
    "service = QiskitRuntimeService(instance='ibm-q-internal/performance/reservations')\n",
    "\n",
    "# # IBMQ.load_account()\n",
    "# provider = IBMProvider(name=\"staging\")\n",
    "# backend = provider.get_backend('ibm_montecarlo')\n",
    "# cmap_gen = GateDirection(backend=backend).coupling_map\n",
    "# coupling_map = list(cmap_gen.get_edges())\n",
    "# coupling_map = [tuple(pair) for pair in coupling_map]\n",
    "\n",
    "\n",
    "if SIM:\n",
    "    # backend = service.least_busy(simulator=True)\n",
    "    \n",
    "    if NOISE:\n",
    "        backend = AerSimulator.from_backend(FakeGuadalupeV2(), seed_simulator=42)\n",
    "\n",
    "    else:\n",
    "        backend = AerSimulator()\n",
    "\n",
    "else:\n",
    "    # backend_id = 'ibm_pinguino1'\n",
    "    # backend_id = 'ibm_torino'\n",
    "    # backend_id = 'ibm_montecarlo'\n",
    "    backend_id = 'ibm_peekskill'\n",
    "    backend = service.backend(backend_id)\n",
    "\n",
    "shots = 30000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: qiskit-ibm-runtime\n",
      "Version: 0.24.0\n",
      "Summary: IBM Quantum client for Qiskit Runtime.\n",
      "Home-page: https://github.com/Qiskit/qiskit-ibm-runtime\n",
      "Author: Qiskit Development Team\n",
      "Author-email: qiskit@us.ibm.com\n",
      "License: Apache 2.0\n",
      "Location: /Users/mirko/opt/miniconda3/envs/krylov-1.0/lib/python3.12/site-packages\n",
      "Requires: ibm-platform-services, numpy, pydantic, python-dateutil, qiskit, requests, requests-ntlm, urllib3, websocket-client\n",
      "Required-by: mthree, pea-summit\n"
     ]
    }
   ],
   "source": [
    "!pip show qiskit-ibm-runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from qiskit_ibm_runtime import QiskitRuntimeService, Session, Batch\n",
    "# from qiskit_ibm_runtime.fake_provider import FakeTorino, FakeGuadalupeV2\n",
    "# from qiskit_aer import AerSimulator\n",
    "\n",
    "\n",
    "# SIM = True\n",
    "# NOISE = False\n",
    "\n",
    "\n",
    "# backend = AerSimulator()\n",
    "\n",
    "# shots = 300000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from qiskit_ibm_provider import IBMProvider\n",
    "# from qiskit_aer import AerSimulator\n",
    "# from qiskit_ibm_runtime import QiskitRuntimeService, Session, Batch\n",
    "\n",
    "\n",
    "# SIM = False\n",
    "# NOISE = False\n",
    "\n",
    "# # IBMQ.load_account()\n",
    "# provider = IBMProvider(name=\"staging\")\n",
    "# backend = provider.get_backend('ibm_montecarlo')\n",
    "# shots = 300000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpile + schedule with DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import XGate, YGate, RZGate\n",
    "from qiskit.transpiler import InstructionProperties\n",
    "from qiskit.transpiler import PassManager\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "from qiskit.transpiler.passes.scheduling import (\n",
    "    ALAPScheduleAnalysis,\n",
    "    PadDynamicalDecoupling,\n",
    ")\n",
    "\n",
    "if not SIM:\n",
    "\n",
    "\n",
    "    target = backend.target\n",
    "    basis_gates = list(target.operation_names)\n",
    "\n",
    "\n",
    "    X = XGate()\n",
    "    Y = YGate()\n",
    "    \n",
    "    # dd_sequence = [X, X, X, X]\n",
    "\n",
    "    dd_sequence=[XGate(), RZGate(np.pi), XGate(), RZGate(-np.pi)]\n",
    "    spacing = [1 / 4, 1 / 2, 0, 0, 1 / 4]\n",
    "\n",
    "\n",
    "    \n",
    "    y_gate_properties = {}\n",
    "    for qubit in range(target.num_qubits):\n",
    "        y_gate_properties.update(\n",
    "            {\n",
    "                (qubit,): InstructionProperties(\n",
    "                    duration=target[\"x\"][(qubit,)].duration,\n",
    "                    error=target[\"x\"][(qubit,)].error,\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "    if 'y' not in target.operation_names:\n",
    "        target.add_instruction(YGate(), y_gate_properties)\n",
    "\n",
    "    pm = generate_preset_pass_manager(optimization_level=3, backend=backend, basis_gates=basis_gates)\n",
    "\n",
    "\n",
    "    pm.scheduling = PassManager(\n",
    "        [\n",
    "            ALAPScheduleAnalysis(target=target),\n",
    "            PadDynamicalDecoupling(target=target, dd_sequence=dd_sequence, spacing=spacing),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    S_real_circ_trans = pm.run(S_real_circ)\n",
    "    S_imag_circ_trans = pm.run(S_imag_circ)\n",
    "\n",
    "    H_real_circ_trans = pm.run(H_real_circ)\n",
    "    H_imag_circ_trans = pm.run(H_imag_circ)\n",
    "\n",
    "elif SIM and NOISE:\n",
    "    target = backend.target\n",
    "    basis_gates = list(target.operation_names)\n",
    "    pm = generate_preset_pass_manager(optimization_level=3, backend=backend, basis_gates=basis_gates)\n",
    "\n",
    "    S_real_circ_trans = pm.run(S_real_circ)\n",
    "    S_imag_circ_trans = pm.run(S_imag_circ)\n",
    "\n",
    "    H_real_circ_trans = pm.run(H_real_circ)\n",
    "    H_imag_circ_trans = pm.run(H_imag_circ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "S_real_circ_trans = S_real_circ\n",
    "S_imag_circ_trans = S_imag_circ\n",
    "\n",
    "H_real_circ_trans = H_real_circ\n",
    "H_imag_circ_trans = H_imag_circ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_real_circ_trans.draw('mpl', fold=-1, idle_wires=False, scale=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_real_circ_trans.depth(lambda x: x[0].num_qubits==2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_real_circ_trans.count_ops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_real_circ.decompose().count_ops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from qiskit.visualization import timeline_drawer\n",
    "# from qiskit.transpiler.passes.scheduling import ALAPSchedule\n",
    "# from qiskit.transpiler import PassManager, InstructionDurations\n",
    "\n",
    "# b_circ = S_real_circ_trans_dd.assign_parameters({t:1})\n",
    "# durations = InstructionDurations().from_backend(backend)\n",
    "# pm = PassManager([ALAPSchedule(durations=durations)])\n",
    "# sched_circ = pm.run(b_circ)\n",
    "\n",
    "# timeline_drawer(sched_circ, show_idle=False)\n",
    "# # timeline_drawer(b_circ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define observables to measure for S\n",
    "observable = 'I'*(n_qubits) + 'Z'\n",
    "\n",
    "if not SIM or (SIM and NOISE):\n",
    "\n",
    "    layout = S_real_circ_trans.layout\n",
    "\n",
    "    observable_op = SparsePauliOp(observable)\n",
    "    observable_op = observable_op.apply_layout(layout)\n",
    "    observable = observable_op.paulis.to_labels()\n",
    "\n",
    "\n",
    "# Define a set of observables to measure\n",
    "else:\n",
    "    observable = ['I'*(n_qubits) + 'Z']\n",
    "\n",
    "observables_S = [observable]\n",
    "\n",
    "# Define a sweep over parameter values\n",
    "params = np.vstack(parameters).T\n",
    "\n",
    "# Estimate the expectation value for all combinations of\n",
    "# observables and parameter values, where the pub result will have\n",
    "# shape (# observables, # parameter values).\n",
    "\n",
    "if not SIM or (SIM and NOISE):\n",
    "    pub_S_real = (S_real_circ_trans, observables_S, params)\n",
    "    pub_S_imag = (S_imag_circ_trans, observables_S, params)\n",
    "else:\n",
    "    pub_S_real = (S_real_circ, observables_S, params)\n",
    "    pub_S_imag = (S_imag_circ, observables_S, params)\n",
    "\n",
    "\n",
    "\n",
    "# Define observables to measure for H\n",
    "# Hamiltonian terms to measure\n",
    "observable_list = []\n",
    "for pauli, coeff in zip(H_op.paulis, H_op.coeffs):\n",
    "    # print(pauli)\n",
    "    observable = pauli[::-1].to_label() + 'Z'\n",
    "    observable_list.append([observable])\n",
    "\n",
    "\n",
    "if not SIM or (SIM and NOISE):\n",
    "\n",
    "    layout = H_real_circ_trans.layout\n",
    "\n",
    "    observable_trans_list = []\n",
    "    for observable in observable_list:\n",
    "        observable_op = SparsePauliOp(observable)\n",
    "        observable_op = observable_op.apply_layout(layout)\n",
    "        observable_trans_list.append(observable_op.paulis.to_labels())\n",
    "\n",
    "    observable_list = observable_trans_list\n",
    "\n",
    "\n",
    "observables_H = observable_list\n",
    "\n",
    "\n",
    "\n",
    "if not SIM or (SIM and NOISE):\n",
    "    pub_H_real = (H_real_circ_trans, observables_H, params)\n",
    "    pub_H_imag = (H_imag_circ_trans, observables_H, params)\n",
    "else:\n",
    "    pub_H_real = (H_real_circ, observables_H, params)\n",
    "    pub_H_imag = (H_imag_circ, observables_H, params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Circuits for $t=0$ are classically calculable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.quantum_info import StabilizerState, Pauli\n",
    "\n",
    "\n",
    "\n",
    "H_real_circ_cliff = H_real_circ.assign_parameters({t:0})\n",
    "H_imag_circ_cliff = H_imag_circ.assign_parameters({t:0})\n",
    "S_real_circ_cliff = S_real_circ.assign_parameters({t:0})\n",
    "S_imag_circ_cliff = S_imag_circ.assign_parameters({t:0})\n",
    "\n",
    "observables_S_cliff = 'I'*(n_qubits) + 'Z'\n",
    "\n",
    "observables_H_cliff = []\n",
    "for pauli, coeff in zip(H_op.paulis, H_op.coeffs):\n",
    "    # print(pauli)\n",
    "    observable = pauli[::-1].to_label() + 'Z'\n",
    "    observables_H_cliff.append(observable)\n",
    "\n",
    "\n",
    "\n",
    "# Get expectation values from experiment\n",
    "S_expval_real = StabilizerState(S_real_circ_cliff).expectation_value(Pauli('I'*(n_qubits) + 'Z'))\n",
    "S_expval_imag = StabilizerState(S_imag_circ_cliff).expectation_value(Pauli('I'*(n_qubits) + 'Z'))\n",
    "\n",
    "# Get expectation values\n",
    "S_expval = S_expval_real + 1j*S_expval_imag\n",
    "\n",
    "H_expval = 0\n",
    "for obs_idx, (pauli, coeff) in enumerate(zip(H_op.paulis, H_op.coeffs)):\n",
    "    # Get expectation values from experiment\n",
    "    expval_real = StabilizerState(H_real_circ_cliff).expectation_value(Pauli(observables_H_cliff[obs_idx]))\n",
    "    expval_imag = StabilizerState(H_imag_circ_cliff).expectation_value(Pauli(observables_H_cliff[obs_idx]))\n",
    "    expval = expval_real + 1j*expval_imag\n",
    "\n",
    "\n",
    "    # Fill-in matrix elements\n",
    "    H_expval += coeff*expval\n",
    "\n",
    "\n",
    "H_expval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute circuits for $\\tilde{S}$ and $\\tilde{H}$ with the Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "OptionsError",
     "evalue": "Error(s) when trying to set an option in EstimatorOptions:\n * experimental: This option doesn't exist. The valid option names for EstimatorOptions are:\n   - default_precision\n   - default_shots\n   - seed_estimator\n   - user_messenger\n   - skip_transpilation\n   - require_isa_circuits\n   - pauli_grouping_fn\n   - dynamical_decoupling\n   - execution\n   - resilience\n   - transpilation\n   - twirling",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/miniconda3/envs/krylov-1.0/lib/python3.12/site-packages/pec_runtime/containers/options.py:138\u001b[0m, in \u001b[0;36mBaseOptions.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/krylov-1.0/lib/python3.12/site-packages/pydantic/main.py:171\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    170\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for EstimatorOptions\nexperimental\n  Extra inputs are not permitted [type=extra_forbidden, input_value={'execution': {'max_pubs_...5, 0.75, 1, 1.3, 1.6]}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/extra_forbidden",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOptionsError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 68\u001b[0m\n\u001b[1;32m     14\u001b[0m options \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Builtin resilience settings for ZNE\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresilience\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     }\n\u001b[1;32m     65\u001b[0m }\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Estimator\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[43mEstimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# # estimator.options.default_shots = 3000\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# # twirling\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# job_H_real = estimator.run([pub_H_real])\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# job_H_imag = estimator.run([pub_H_imag])\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/krylov-1.0/lib/python3.12/site-packages/pec_runtime/primitives/estimator_v2.py:155\u001b[0m, in \u001b[0;36mEstimatorV2.__init__\u001b[0;34m(self, backend, session, resilience_level, options)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resilience_level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# ensure we don't change the instance when EstimatorOptions are given\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    153\u001b[0m         options\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(options, EstimatorOptions)\n\u001b[0;32m--> 155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mEstimatorOptions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# ensure we update with given options _after_ we grab the resilience level defaults\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options \u001b[38;5;241m=\u001b[39m EstimatorOptions\u001b[38;5;241m.\u001b[39mpreset(resilience_level\u001b[38;5;241m=\u001b[39mresilience_level)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/krylov-1.0/lib/python3.12/site-packages/pec_runtime/containers/options.py:140\u001b[0m, in \u001b[0;36mBaseOptions.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OptionsError(err, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mOptionsError\u001b[0m: Error(s) when trying to set an option in EstimatorOptions:\n * experimental: This option doesn't exist. The valid option names for EstimatorOptions are:\n   - default_precision\n   - default_shots\n   - seed_estimator\n   - user_messenger\n   - skip_transpilation\n   - require_isa_circuits\n   - pauli_grouping_fn\n   - dynamical_decoupling\n   - execution\n   - resilience\n   - transpilation\n   - twirling"
     ]
    }
   ],
   "source": [
    "from pec_runtime.primitives import EstimatorV2 as Estimator\n",
    "\n",
    "\n",
    "\n",
    "# Experiment options\n",
    "num_randomizations = 500\n",
    "num_randomizations_learning = 10\n",
    "max_batch_circuits = 20\n",
    "shots_per_randomization = 100\n",
    "learning_pair_depths = [0, 4, 24]\n",
    "noise_factors = [1, 1.3, 1.6]\n",
    "\n",
    "# Base option formatting\n",
    "options = {\n",
    "    # Builtin resilience settings for ZNE\n",
    "    \"resilience\": {\n",
    "        \"measure_mitigation\": True,\n",
    "        \"zne_mitigation\": True,\n",
    "        \"zne\": {\"noise_factors\": noise_factors},\n",
    "\n",
    "        # TREX noise learning configuration\n",
    "        \"measure_noise_learning\": {\n",
    "            \"num_randomizations\": num_randomizations_learning,\n",
    "            \"shots_per_randomization\": shots_per_randomization,\n",
    "        },\n",
    "        \n",
    "        # PEA noise model configuration\n",
    "        \"layer_noise_learning\": {\n",
    "            \"max_layers_to_learn\": 10,\n",
    "            \"layer_pair_depths\": learning_pair_depths,\n",
    "            \"shots_per_randomization\": shots_per_randomization,\n",
    "            \"num_randomizations\": num_randomizations_learning,\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    # Randomization configuration\n",
    "    \"twirling\": {\n",
    "        \"num_randomizations\": num_randomizations,\n",
    "        \"shots_per_randomization\": shots_per_randomization,\n",
    "        \"strategy\": \"all\",\n",
    "    },\n",
    "\n",
    "    # Experimental settings for PEA method\n",
    "    \"experimental\": {\n",
    "        # # Just in case, disable any further qiskit transpilation not related to twirling / DD\n",
    "        # \"skip_transpilation\": True,\n",
    "\n",
    "        # Execution configuration\n",
    "        \"execution\": {\n",
    "            \"max_pubs_per_batch_job\": max_batch_circuits,\n",
    "            \"fast_parametric_update\": True,\n",
    "        },\n",
    "\n",
    "        # Error Mitigation configuration\n",
    "        \"resilience\": {\n",
    "            # ZNE Configuration\n",
    "            \"zne\": {\n",
    "                \"amplifier\": \"pea\",\n",
    "                \"return_all_extrapolated\": True,\n",
    "                \"return_unextrapolated\": True,\n",
    "                \"extrapolated_noise_factors\": [0, 0.25, 0.5, 0.75] + noise_factors,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Estimator\n",
    "estimator = Estimator(backend, options=options)\n",
    "\n",
    "# # estimator.options.default_shots = 3000\n",
    "\n",
    "# # twirling\n",
    "# estimator.options.twirling.shots_per_randomization = 100\n",
    "# estimator.options.twirling.num_randomizations = 500\n",
    "# estimator.options.twirling.strategy = 'all'\n",
    "\n",
    "# # DD\n",
    "# estimator.options.dynamical_decoupling.enable = True\n",
    "# estimator.options.dynamical_decoupling.sequence_type = 'XY4'\n",
    "\n",
    "\n",
    "# # Additional options to enable and modify PEA based ZNE\n",
    "# estimator.options.resilience.zne.amplifier = \"pea\"\n",
    "# estimator.options.resilience.zne.noise_factors = [1, 1.3, 1.6]\n",
    "\n",
    "# #trex\n",
    "# estimator.options.resilience.measure_noise_learning.num_randomizations = 100\n",
    "# estimator.options.resilience.measure_noise_learning.shots_per_randomization = 100\n",
    "\n",
    "# #pea learning\n",
    "# estimator.options.resilience.layer_noise_learning.layer_pair_depths = [0, 4, 24]\n",
    "# estimator.options.resilience.layer_noise_learning.shots_per_randomization = 100\n",
    "# estimator.options.resilience.layer_noise_learning.num_randomizations = 15\n",
    "\n",
    "# # experimental options\n",
    "# estimator.options.experimental.execution.fast_parametric_update = True\n",
    "# estimator.options.experimental.resilience.zne.amplifier = 'pea'\n",
    "# estimator.options.experimental.resilience.zne.return_all_extrapolated = True\n",
    "# estimator.options.experimental.resilience.zne.return_unextrapolated = True\n",
    "# estimator.options.experimental.resilience.zne.extrapolated_noise_factors = [1, 1.3, 1.6]\n",
    "\n",
    "\n",
    "# job_S_real = estimator.run([pub_S_real])\n",
    "# job_S_imag = estimator.run([pub_S_imag])\n",
    "# job_H_real = estimator.run([pub_H_real])\n",
    "# job_H_imag = estimator.run([pub_H_imag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_ibm_runtime.options.estimator_options import EstimatorOptions\n",
    "\n",
    "# Experiment options\n",
    "num_randomizations = 500\n",
    "num_randomizations_learning = 10\n",
    "max_batch_circuits = 20\n",
    "shots_per_randomization = 100\n",
    "learning_pair_depths = [0, 4, 24]\n",
    "noise_factors = [1, 1.3, 1.6]\n",
    "\n",
    "# # Base option formatting\n",
    "# options = {\n",
    "#     # Builtin resilience settings for ZNE\n",
    "#     \"resilience\": {\n",
    "#         \"measure_mitigation\": True,\n",
    "#         \"zne_mitigation\": True,\n",
    "#         \"zne\": {\"noise_factors\": noise_factors},\n",
    "\n",
    "#         # TREX noise learning configuration\n",
    "#         \"measure_noise_learning\": {\n",
    "#             \"num_randomizations\": num_randomizations_learning,\n",
    "#             \"shots_per_randomization\": shots_per_randomization,\n",
    "#         },\n",
    "        \n",
    "#         # PEA noise model configuration\n",
    "#         \"layer_noise_learning\": {\n",
    "#             \"max_layers_to_learn\": 10,\n",
    "#             \"layer_pair_depths\": learning_pair_depths,\n",
    "#             \"shots_per_randomization\": shots_per_randomization,\n",
    "#             \"num_randomizations\": num_randomizations_learning,\n",
    "#         },\n",
    "#     },\n",
    "    \n",
    "#     # Randomization configuration\n",
    "#     \"twirling\": {\n",
    "#         \"num_randomizations\": num_randomizations,\n",
    "#         \"shots_per_randomization\": shots_per_randomization,\n",
    "#         \"strategy\": \"all\",\n",
    "#     },\n",
    "# }\n",
    "\n",
    "exp_opt = {\n",
    "    # Experimental settings for PEA method\n",
    "    \"experimental\": {\n",
    "        # # Just in case, disable any further qiskit transpilation not related to twirling / DD\n",
    "        # \"skip_transpilation\": True,\n",
    "\n",
    "        # Execution configuration\n",
    "        \"execution\": {\n",
    "            \"max_pubs_per_batch_job\": max_batch_circuits,\n",
    "            \"fast_parametric_update\": True,\n",
    "        },\n",
    "\n",
    "        # Error Mitigation configuration\n",
    "        \"resilience\": {\n",
    "            # ZNE Configuration\n",
    "            \"zne\": {\n",
    "                \"amplifier\": \"pea\",\n",
    "                \"return_all_extrapolated\": True,\n",
    "                \"return_unextrapolated\": True,\n",
    "                \"extrapolated_noise_factors\": [0, 0.25, 0.5, 0.75] + noise_factors,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "estimator_options = EstimatorOptions()\n",
    "estimator_options.experimental = exp_opt\n",
    "\n",
    "\n",
    "# Estimator\n",
    "estimator = Estimator(backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "property 'options' of 'EstimatorV2' object has no setter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m \u001b[38;5;241m=\u001b[39m estimator_options\n",
      "\u001b[0;31mAttributeError\u001b[0m: property 'options' of 'EstimatorV2' object has no setter"
     ]
    }
   ],
   "source": [
    "estimator.options = estimator_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if SIM:\n",
    "#     with Session(backend=backend) as session:\n",
    "#         estimator = Estimator(session=session)\n",
    "#         job_S_real = estimator.run([pub_S_real], precision=1/np.sqrt(shots))\n",
    "#         job_S_imag = estimator.run([pub_S_imag], precision=1/np.sqrt(shots))\n",
    "#         job_H_real = estimator.run([pub_H_real], precision=1/np.sqrt(shots))\n",
    "#         job_H_imag = estimator.run([pub_H_imag], precision=1/np.sqrt(shots))\n",
    "\n",
    "# else:\n",
    "#     with Batch(backend=backend) as batch:\n",
    "\n",
    "#         estimator = Estimator(session=batch, options={\"resilience_level\": 1, \"experimental\": {\"execution\": {\"fast_parametric_update\" : True}}})\n",
    "\n",
    "#         # estimator.options.resilience.zne_mitigation=True\n",
    "#         # estimator.options.resilience.zne.extrapolator='linear'\n",
    "#         # estimator.options.resilience.zne.noise_factors = [1,1.3,1.6]\n",
    "\n",
    "#         job_S_real = estimator.run([pub_S_real], precision=1/np.sqrt(shots))\n",
    "#         job_S_imag = estimator.run([pub_S_imag], precision=1/np.sqrt(shots))\n",
    "#         job_H_real = estimator.run([pub_H_real], precision=1/np.sqrt(shots))\n",
    "#         job_H_imag = estimator.run([pub_H_imag], precision=1/np.sqrt(shots))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_S_real_id = job_S_real.job_id()\n",
    "job_S_imag_id = job_S_imag.job_id()\n",
    "job_H_real_id = job_H_real.job_id()\n",
    "job_H_imag_id = job_H_imag.job_id()\n",
    "print(job_S_real_id)\n",
    "print(job_S_imag_id)\n",
    "print(job_H_real_id)\n",
    "print(job_H_imag_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Post-process and analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_real_results = job_S_real.result()[0]\n",
    "S_imag_results = job_S_imag.result()[0]\n",
    "H_real_results = job_H_real.result()[0]\n",
    "H_imag_results = job_H_imag.result()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qubit = 0\n",
    "pub_result = job_S_real.result()[0]\n",
    "values = np.asarray(pub_result.data.evs, dtype=float)\n",
    "stderrs = np.asarray(pub_result.data.stds, dtype=float)\n",
    "metadata = pub_result.metadata\n",
    "num_params = values.shape[1]\n",
    "\n",
    "extraps = np.asarray(metadata[\"resilience\"][\"zne_extrapolator\"], dtype=object)[\n",
    "    qubit\n",
    "]\n",
    "# Get raw data noise factors from metadata\n",
    "noise_factors = np.asarray(\n",
    "    metadata[\"resilience\"][\"zne_noise_factors\"], dtype=float\n",
    ")[qubit]\n",
    "raw_idx = extraps[0, 1] == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_S_real.result().metadata#['resilience']['zne_extrapolator'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefactors = []\n",
    "E0t_array = []\n",
    "for i, circ in enumerate(iter(qc_evol.assign_parameters([(i*dt)/num_trotter_steps]) for i in range(1, krylov_dim))):\n",
    "    phase = 1.0\n",
    "    E0t = 0\n",
    "    for instruction in circ.data:\n",
    "        if instruction.operation.name != 'swap' and instruction.operation.name != 'barrier':\n",
    "            # All the non-swap gates are XX+YY+ZZ rotations, which add a phase to the all-zeros state.\n",
    "            if instruction.operation.params:\n",
    "                E0t += float(instruction.operation.params[0])\n",
    "                # phase *= np.exp(1j*float(instruction.operation.params[0])/2)\n",
    "                phase *= np.exp(-1j*float(instruction.operation.params[0])/2) # NY added, we need to `subtract` the E0 * t so minus sign\n",
    "            # assert(float(instruction.operation.params[0]._symbol_expr) == i*dt/n_T_step)\n",
    "    prefactors.append(phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the results of the circuit executions we can post-process the data to calculate the matrix elements of $\\tilde{S}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# Assemble S, the overlap matrix of dimension D:\n",
    "S_first_row = np.zeros(krylov_dim, dtype=complex)\n",
    "S_first_row[0] = 1+0j\n",
    "\n",
    "# Add in ancilla-only measurements:\n",
    "for i in range(krylov_dim-1):\n",
    "\n",
    "    # Get expectation values from experiment\n",
    "    expval_real = S_real_results.data.evs[0][i]\n",
    "    expval_imag = S_imag_results.data.evs[0][i]\n",
    "\n",
    "    # Get expectation values\n",
    "    expval = expval_real + 1j*expval_imag\n",
    "    # Get the coefficients and expectation values corresponding to actual terms in the Hamiltonian (as opposed to the ancilla-only measurements).\n",
    "    S_first_row[i+1] += prefactors[i]*expval\n",
    "\n",
    "S_first_row_list =  S_first_row.tolist() #for saving purposes     \n",
    "            \n",
    "            \n",
    "S_circ = np.zeros((krylov_dim, krylov_dim), dtype=complex)\n",
    "\n",
    "# Distribute entries from first row across matrix:\n",
    "for i,j in itertools.product(range(krylov_dim),repeat=2):\n",
    "    if i >= j:\n",
    "        S_circ[j,i] = S_first_row[i-j]\n",
    "    else:\n",
    "        S_circ[j,i] = np.conj(S_first_row[j-i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import Matrix\n",
    "Matrix(S_circ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the matrix elements of $\\tilde{H}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# Assemble S, the overlap matrix of dimension D:\n",
    "H_first_row = np.zeros(krylov_dim, dtype=complex)\n",
    "H_first_row[0] = H_expval\n",
    "\n",
    "for obs_idx, (pauli, coeff) in enumerate(zip(H_op.paulis, H_op.coeffs)):\n",
    "    # Add in ancilla-only measurements:\n",
    "    for i in range(krylov_dim-1):\n",
    "\n",
    "        # Get expectation values from experiment\n",
    "        expval_real = H_real_results.data.evs[obs_idx][i]\n",
    "        expval_imag = H_imag_results.data.evs[obs_idx][i]\n",
    "\n",
    "        # Get expectation values\n",
    "        expval = expval_real + 1j*expval_imag\n",
    "        # Get the coefficients and expectation values corresponding to actual terms in the Hamiltonian (as opposed to the ancilla-only measurements).\n",
    "        H_first_row[i+1] += prefactors[i]*coeff*expval\n",
    "        \n",
    "H_first_row_list = H_first_row.tolist()           \n",
    "            \n",
    "H_eff_circ = np.zeros((krylov_dim, krylov_dim), dtype=complex)\n",
    "\n",
    "# Distribute entries from first row across matrix:\n",
    "for i,j in itertools.product(range(krylov_dim),repeat=2):\n",
    "    if i >= j:\n",
    "        H_eff_circ[j,i] = H_first_row[i-j]\n",
    "    else:\n",
    "        H_eff_circ[j,i] = np.conj(H_first_row[j-i])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import Matrix\n",
    "Matrix(H_eff_circ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can solve the generalized eigenvalue problem for $\\tilde{H}$:\n",
    "\n",
    "$$\\tilde{H} \\vec{c} = c \\tilde{S} \\vec{c}$$\n",
    "\n",
    "and get an estimate of the ground state energy $c_{min}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnd_en_circ_est_list = []\n",
    "for d in range(1, krylov_dim+1):\n",
    "    # Solve generalized eigenvalue problem\n",
    "    gnd_en_circ_est = solve_regularized_gen_eig(H_eff_circ[:d, :d], S_circ[:d, :d], threshold=6e-1)\n",
    "    gnd_en_circ_est_list.append(gnd_en_circ_est)\n",
    "    print('The estimated ground state energy is: ', gnd_en_circ_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(np.linalg.eigvals(S_circ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_en = min(sp.sparse.linalg.eigsh(H_op.to_matrix(), which = \"SA\", k = 10)[0])\n",
    "print('gs_en', gs_en)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_en = single_particle_gs(H_op, n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(1, krylov_dim+1), gnd_en_circ_est_list_0, color = 'blue', linestyle='-.' , label = 'estimate - res 0 ')\n",
    "# plt.plot(range(1, krylov_dim+1), gnd_en_circ_est_list_1, color = 'yellow', linestyle='-.' , label = 'estimate - res 1 ')\n",
    "# plt.plot(range(1, krylov_dim+1), gnd_en_circ_est_list_2, color = 'green', linestyle='-.' , label = 'estimate - res 2')\n",
    "plt.plot(range(1, krylov_dim+1), gnd_en_circ_est_list, color = 'orange', linestyle='-.' , label = 'estimate - res 2 heron')\n",
    "plt.plot(range(1, krylov_dim+1), [gs_en]*krylov_dim, color = 'red', linestyle='-' , label = 'exact')\n",
    "plt.xticks(range(1, krylov_dim+1), range(1, krylov_dim+1))\n",
    "plt.legend()\n",
    "plt.xlabel('Krylov space dimension')\n",
    "plt.ylabel('Energy')\n",
    "plt.title('Estimating Ground state energy with Quantum Krylov')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools    \n",
    "\n",
    "U = sp.linalg.expm(-1j*H_op.to_matrix()*dt) # time-evolution operator\n",
    "\n",
    "## Start from a random state |psi_0> as the reference state for the unitary krylov subspace\n",
    "init = np.random.uniform(0, 1, size = 2**n_qubits)*(1+0j)\n",
    "norm_init = np.linalg.norm(init)\n",
    "init = init/np.sqrt(norm_init)\n",
    "\n",
    "\n",
    "# Get different powers of U\n",
    "u_krylov_ops = [np.eye(2**n_qubits, dtype=complex)]\n",
    "op = u_krylov_ops[0]\n",
    "for i in range(1, krylov_dim):\n",
    "    op = op @ U\n",
    "    u_krylov_ops.append(op)\n",
    "\n",
    "# Get vectors of the Krylov subspace\n",
    "u_krylov_vecs = [op @ init for op in u_krylov_ops]\n",
    "\n",
    "# Calculate the overlap matrix <psi_i|psi_j> where |psi_i> = U^i |psi_0>\n",
    "S_first_row = []\n",
    "for i in range(krylov_dim):\n",
    "    s = u_krylov_vecs[0].T.conj() @ u_krylov_vecs[i]\n",
    "    S_first_row.append(s)\n",
    "print(S_first_row)\n",
    "\n",
    "# Calculate the expectation values of H in the subspace <psi_i|H|psi_j>\n",
    "H_first_row = []\n",
    "for i in range(krylov_dim):\n",
    "    h = u_krylov_vecs[0].T.conj()@ H_op.to_matrix() @ u_krylov_vecs[i]\n",
    "    H_first_row.append(h)\n",
    "print(H_first_row)\n",
    "\n",
    "\n",
    "S = np.zeros((krylov_dim, krylov_dim), dtype=complex)\n",
    "# Distribute entries from first row across matrix:\n",
    "for i,j in itertools.product(range(krylov_dim),repeat=2):\n",
    "    if i >= j:\n",
    "        S[j,i] = S_first_row[i-j]\n",
    "    else:\n",
    "        S[j,i] = np.conj(S_first_row[j-i])\n",
    "\n",
    "\n",
    "H_eff = np.zeros((krylov_dim, krylov_dim), dtype=complex)\n",
    "# Distribute entries from first row across matrix:\n",
    "for i,j in itertools.product(range(krylov_dim),repeat=2):\n",
    "    if i >= j:\n",
    "        H_eff[j,i] = H_first_row[i-j]\n",
    "    else:\n",
    "        H_eff[j,i] = np.conj(H_first_row[j-i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate ground state with increasing number of vector in the subspace (up to the number define at the beginning)\n",
    "gnd_en_num_est_list = []\n",
    "for d in range(1, krylov_dim+1):\n",
    "    # Solve generalized eigenvalue problem\n",
    "    gnd_en_circ_est = solve_regularized_gen_eig(H_eff[:d, :d], S[:d, :d], threshold=1e-10)\n",
    "    gnd_en_num_est_list.append(gnd_en_circ_est)\n",
    "    print('The estimated ground state energy is: ', gnd_en_circ_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Paulis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theory calculation (phase issue with real expvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS FUNCTION CALCULATES THE PAULI MATRICES FOR EACH DIMENSION IN d_list, USING NOBU'S k-PARTICLE CODE\n",
    "# Note that passing in vectors_kp is optional but if you already have it from the Krylov matrix calculation, it can save time.\n",
    "from utils_k_particle import compute_pauli_matrices\n",
    "from utils_k_particle import get_indexes_for_m_particles, k_particle_excitation, simulate_unitary_kparticle_from_interaction_list\n",
    "\n",
    "fixed_control = 0\n",
    "excitations = [int(n_qubits/2)+1]\n",
    "H = H_op     \n",
    "\n",
    "k = len(excitations)\n",
    "indices = get_indexes_for_m_particles(n_qubits, k)\n",
    "\n",
    "initial_state_kp = k_particle_excitation(n_qubits, excitations, indices)\n",
    "vectors_kp = [simulate_unitary_kparticle_from_interaction_list(interaction_list, initial_state_kp, n_qubits, k, num_trotter_steps, param = (i*dt)/num_trotter_steps, as_sparse = True) for i in range(krylov_dim)]\n",
    "\n",
    "all_exp_vals, vectors_kp = compute_pauli_matrices(n_qubits, fixed_control, excitations, H, interaction_list, num_trotter_steps, dt, list(range(krylov_dim)), vectors_kp)\n",
    "\n",
    "\n",
    "\n",
    "H_first_row_exact = np.zeros(krylov_dim, dtype=complex)\n",
    "prefactors_exact = [1+0j] + prefactors\n",
    "for i, expvals_dict in enumerate(all_exp_vals):\n",
    "\n",
    "\n",
    "    res_dict_sim = {}\n",
    "    for obs_idx, (pauli, coeff) in enumerate(zip(H_op.paulis, H_op.coeffs)):\n",
    "        # Get expectation values from experiment\n",
    "        obs = observables_H_cliff[obs_idx]\n",
    "        new_obs = obs[:-1]\n",
    "        expval_real = expvals_dict[new_obs + 'X']\n",
    "        expval_imag = expvals_dict[new_obs + 'Y']\n",
    "\n",
    "\n",
    "        expval = expval_real + 1j*expval_imag\n",
    "\n",
    "        H_first_row_exact[i] += prefactors_exact[i]*coeff*expval\n",
    "\n",
    "\n",
    "\n",
    "H_first_row_exact_list = H_first_row_exact.tolist()           \n",
    "            \n",
    "H_eff_circ_exact = np.zeros((krylov_dim, krylov_dim), dtype=complex)\n",
    "\n",
    "# Distribute entries from first row across matrix:\n",
    "for i,j in itertools.product(range(krylov_dim),repeat=2):\n",
    "    if i >= j:\n",
    "        H_eff_circ_exact[j,i] = H_first_row_exact[i-j]\n",
    "    else:\n",
    "        H_eff_circ_exact[j,i] = np.conj(H_first_row_exact[j-i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matrix(H_eff_circ_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical calculation (few qubits only!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.quantum_info import Statevector, Pauli\n",
    "\n",
    "H_first_row_sim = np.zeros(krylov_dim, dtype=complex)\n",
    "H_first_row_sim[0] = H_expval\n",
    "\n",
    "S_first_row_sim = np.zeros(krylov_dim, dtype=complex)\n",
    "S_first_row_sim[0] = 1+0j\n",
    "\n",
    "all_exp_vals_sim = []\n",
    "for i, param in enumerate(parameters):\n",
    "\n",
    "    H_real_circ_cliff = H_real_circ.assign_parameters({t:param})\n",
    "    H_imag_circ_cliff = H_imag_circ.assign_parameters({t:param})\n",
    "    S_real_circ_cliff = S_real_circ.assign_parameters({t:param})\n",
    "    S_imag_circ_cliff = S_imag_circ.assign_parameters({t:param})\n",
    "\n",
    "    observables_S_cliff = 'I'*(n_qubits) + 'Z'\n",
    "\n",
    "    observables_H_cliff = []\n",
    "    for pauli, coeff in zip(H_op.paulis, H_op.coeffs):\n",
    "        # print(pauli)\n",
    "        observable = pauli[::-1].to_label() + 'Z'\n",
    "        observables_H_cliff.append(observable)\n",
    "\n",
    "\n",
    "\n",
    "    # Get expectation values from experiment\n",
    "    S_expval_real = Statevector(S_real_circ_cliff).expectation_value(Pauli('I'*(n_qubits) + 'Z'))\n",
    "    S_expval_imag = Statevector(S_imag_circ_cliff).expectation_value(Pauli('I'*(n_qubits) + 'Z'))\n",
    "\n",
    "    # Get expectation values\n",
    "    S_expval = S_expval_real + 1j*S_expval_imag\n",
    "\n",
    "    S_first_row_sim[i+1] += prefactors[i]*S_expval\n",
    "\n",
    "\n",
    "    res_dict_sim = {}\n",
    "    for obs_idx, (pauli, coeff) in enumerate(zip(H_op.paulis, H_op.coeffs)):\n",
    "        # Get expectation values from experiment\n",
    "        expval_real = Statevector(H_real_circ_cliff).expectation_value(Pauli(observables_H_cliff[obs_idx]))\n",
    "        expval_imag = Statevector(H_imag_circ_cliff).expectation_value(Pauli(observables_H_cliff[obs_idx]))\n",
    "        obs = observables_H_cliff[obs_idx]\n",
    "        new_obs = obs[:-1]\n",
    "        res_dict_sim[new_obs + 'X'] = expval_real\n",
    "        res_dict_sim[new_obs + 'Y'] = expval_imag\n",
    "\n",
    "\n",
    "        expval = expval_real + 1j*expval_imag\n",
    "\n",
    "\n",
    "        H_first_row_sim[i+1] += prefactors[i]*coeff*expval\n",
    "\n",
    "    all_exp_vals_sim.append(res_dict_sim)\n",
    "\n",
    "\n",
    "H_first_row_sim_list = H_first_row_sim.tolist()           \n",
    "            \n",
    "H_eff_circ_sim = np.zeros((krylov_dim, krylov_dim), dtype=complex)\n",
    "\n",
    "# Distribute entries from first row across matrix:\n",
    "for i,j in itertools.product(range(krylov_dim),repeat=2):\n",
    "    if i >= j:\n",
    "        H_eff_circ_sim[j,i] = H_first_row_sim[i-j]\n",
    "    else:\n",
    "        H_eff_circ_sim[j,i] = np.conj(H_first_row_sim[j-i])\n",
    "\n",
    "            \n",
    "            \n",
    "S_circ_sim = np.zeros((krylov_dim, krylov_dim), dtype=complex)\n",
    "\n",
    "# Distribute entries from first row across matrix:\n",
    "for i,j in itertools.product(range(krylov_dim),repeat=2):\n",
    "    if i >= j:\n",
    "        S_circ_sim[j,i] = S_first_row_sim[i-j]\n",
    "    else:\n",
    "        S_circ_sim[j,i] = np.conj(S_first_row_sim[j-i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnd_en_circ_sim_est_list = []\n",
    "for d in range(1, krylov_dim+1):\n",
    "    # Solve generalized eigenvalue problem\n",
    "    gnd_en_circ_est = solve_regularized_gen_eig(H_eff_circ_sim[:d, :d], S_circ_sim[:d, :d], threshold=4e-2)\n",
    "    gnd_en_circ_sim_est_list.append(gnd_en_circ_est)\n",
    "    print('The estimated ground state energy is: ', gnd_en_circ_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, krylov_dim+1), gnd_en_circ_est_list, color = 'orange', linestyle='-.' , label = 'estimate - res 1 heron')\n",
    "plt.plot(range(1, krylov_dim+1), gnd_en_circ_sim_est_list, color = 'blue', linestyle='-.' , label = 'estimate - sim')\n",
    "plt.plot(range(1, krylov_dim+1), [gs_en]*krylov_dim, color = 'red', linestyle='-' , label = 'exact')\n",
    "plt.xticks(range(1, krylov_dim+1), range(1, krylov_dim+1))\n",
    "plt.legend()\n",
    "plt.xlabel('Krylov space dimension')\n",
    "plt.ylabel('Energy')\n",
    "plt.title('Estimating Ground state energy with Quantum Krylov')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimental values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exp_vals_exp = []\n",
    "for idx in range(krylov_dim-1):\n",
    "    res_dict = {}\n",
    "    for obs_idx, (pauli, coeff) in enumerate(zip(H_op.paulis, H_op.coeffs)):\n",
    "        # Get expectation values from experiment\n",
    "        expval_real = H_real_results.data.evs[obs_idx][idx]\n",
    "        expval_imag = H_imag_results.data.evs[obs_idx][idx]\n",
    "        obs = observables_H_cliff[obs_idx]\n",
    "        new_obs = obs[:-1]\n",
    "        res_dict[new_obs + 'X'] = expval_real\n",
    "        res_dict[new_obs + 'Y'] = expval_imag\n",
    "    all_exp_vals_exp.append(res_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx  = 1\n",
    "for pauli, val in all_exp_vals_exp[idx].items():\n",
    "    \n",
    "    # if pauli[-1] == 'X' and abs(np.round(phase_factor.real, 2)) > 0:\n",
    "    #     all_exp_vals[idx+1][pauli] = phase_factor.real*all_exp_vals[idx+1][pauli]\n",
    "    # if pauli[-1] == 'Y' and abs(np.round(phase_factor.imag, 2)) > 0:\n",
    "    #     all_exp_vals[idx+1][pauli] = phase_factor.imag*all_exp_vals[idx+1][pauli]\n",
    "\n",
    "\n",
    "    print(pauli, np.round(val, 3), np.round(all_exp_vals_sim[idx][pauli],3) )#, np.round(all_exp_vals[idx+1][pauli], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx  = 0\n",
    "for pauli, val in all_exp_vals_exp[idx].items():\n",
    "    if abs(val) > 0.1:\n",
    "        damp_sim = abs(val/all_exp_vals_sim[idx][pauli])\n",
    "        damp_ex = abs(val/all_exp_vals[idx+1][pauli])\n",
    "        print(pauli, np.round(damp_sim, 3), np.round(damp_ex,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "time_string = time.strftime(\"%m%d%Y_%H%M%S\")\n",
    "data_dir_path = f'data/{backend_id}_{n_qubits}q_{time_string}/'\n",
    "# Save experiment parameters\n",
    "var_dict = {k: globals()[k] for k in [ 'n_qubits',\n",
    "                                        'J',\n",
    "                                        'H_tot',\n",
    "                                        'dt',\n",
    "                                        'krylov_dim',\n",
    "                                        'num_trotter_steps',\n",
    "                                        'dt_circ',\n",
    "                                        'parameters',\n",
    "                                        'backend_id',\n",
    "                                        'shots',\n",
    "                                        'observables_S',\n",
    "                                        'observables_H',\n",
    "                                        'pub_S_real',\n",
    "                                        'pub_S_imag',\n",
    "                                        'pub_H_real',\n",
    "                                        'pub_H_imag',\n",
    "                                        'job_S_real_id',\n",
    "                                        'job_S_imag_id',\n",
    "                                        'job_H_real_id',\n",
    "                                        'job_H_imag_id',\n",
    "                                        'S_expval',\n",
    "                                        'H_expval',\n",
    "                                        'prefactors',\n",
    "                                        'S_first_row_list',\n",
    "                                        'H_first_row_list',\n",
    "                                        'n_exc',\n",
    "                                        'gs_en',]}\n",
    "\n",
    "\n",
    "\n",
    "# Save to Box folder (avoid Github large file storage issues)\n",
    "os.makedirs(os.path.dirname(data_dir_path), exist_ok=True)\n",
    "fname = data_dir_path + \"experiment_parameters.pickle\"\n",
    "with open(fname, \"wb\") as f:\n",
    "    pickle.dump(var_dict, f)\n",
    "\n",
    "\n",
    "np.save(data_dir_path + 'S_real_results_evs', S_real_results.data.evs)\n",
    "np.save(data_dir_path + 'S_imag_results_evs', S_imag_results.data.evs)\n",
    "np.save(data_dir_path + 'H_real_results_evs', H_real_results.data.evs)\n",
    "np.save(data_dir_path + 'H_imag_results_evs', H_imag_results.data.evs)\n",
    "\n",
    "np.save(data_dir_path + 'S_real_results_metadata', S_real_results.metadata)\n",
    "np.save(data_dir_path + 'S_imag_results_metadata', S_imag_results.metadata)\n",
    "np.save(data_dir_path + 'H_real_results_metadata', H_real_results.metadata)\n",
    "np.save(data_dir_path + 'H_imag_results_metadata', H_imag_results.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
